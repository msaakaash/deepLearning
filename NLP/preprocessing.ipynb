{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP preprocessing technique"
      ],
      "metadata": {
        "id": "16XDWpLvG4z6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lowercasing"
      ],
      "metadata": {
        "id": "qOu1cMmSG-Hu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEEdxoIIGwf-",
        "outputId": "b4974a73-0ba5-46c5-c5c6-ca0762111e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello!!this is nlp\n"
          ]
        }
      ],
      "source": [
        "text = \"Hello!!This is NLP\"\n",
        "lower_text = text.lower()\n",
        "print(lower_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Punctuations"
      ],
      "metadata": {
        "id": "xoHk3Q6pHJID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "text = \"Hello,there! How's it going??\"\n",
        "text_no_punc = text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "print(text_no_punc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "076nHoP8HImU",
        "outputId": "154d29b5-c67b-4c56-e2b0-11baca1847c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hellothere Hows it going\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing special characters"
      ],
      "metadata": {
        "id": "RtvTmImFHmJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Hello @NLP! #MachineLearning $100 is amazing.\"\n",
        "text_clean = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "print(text_clean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noNaOHK8H9TW",
        "outputId": "3d8c2110-7e4b-45f1-9176-9b4755fa64c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello NLP MachineLearning 100 is amazing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removind stopwords"
      ],
      "metadata": {
        "id": "aCJ5vY9vIUEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "text = \"This is an example of removing stopwords from a sentence.\"\n",
        "filtered_text = \" \".join([word for word in text.split() if word.lower() not in stop_words])\n",
        "print(filtered_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy9MZ8ujILu0",
        "outputId": "7cc3c36b-5785-4728-b9a5-a1c680028be0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example removing stopwords sentence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "OYIFsPRsJKGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "text = \"Tokenization is an important step in NLP. It helps in processing text efficiently.\"\n",
        "word_tokens = word_tokenize(text)\n",
        "sent_tokens = sent_tokenize(text)\n",
        "\n",
        "print(\"Word Tokens:\", word_tokens)\n",
        "print(\"Sentence Tokens:\", sent_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmFuD51IIsG8",
        "outputId": "6f66f693-9867-4191-906e-642d2d9f5101"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Tokens: ['Tokenization', 'is', 'an', 'important', 'step', 'in', 'NLP', '.', 'It', 'helps', 'in', 'processing', 'text', 'efficiently', '.']\n",
            "Sentence Tokens: ['Tokenization is an important step in NLP.', 'It helps in processing text efficiently.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming"
      ],
      "metadata": {
        "id": "1wzAxyzuJ8un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "words = [\"running\", \"flies\", \"easily\", \"playing\"]\n",
        "\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZCP1IkvJOsn",
        "outputId": "a53d735f-216d-43b1-9541-24c740d4ef33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'fli', 'easili', 'play']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization"
      ],
      "metadata": {
        "id": "KjXAZ9MiKfbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [\"running\", \"flies\", \"easily\", \"playing\"]\n",
        "\n",
        "lemmatized_words = [lemmatizer.lemmatize(word, pos=\"v\") for word in words]\n",
        "print(lemmatized_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ObJwbvKet1",
        "outputId": "ca8d81a9-6a73-4d83-8c41-1fe8456ee014"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'fly', 'easily', 'play']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "18lXShdZJXQs"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}